36.66531025099903
161.85523350899894
24.91563289500118
164.6677218069999
26.413114046001283
156.9014184919979
23.95603248399857
157.04816070599918
24.122372230998735
157.11875160300042
26.21698198499871
157.21179572599794
[1] Train loss: 0.725, Train acc: 0.782
[1] Validation loss: 0.357, Validation acc: 0.891
21.004735724003694
157.5045546390029
22.89159243600443
157.27994961299555
21.984827841995866
157.47777742700418
23.706784294998215
157.3121614479969
23.52674712800217
157.68682069199713
[2] Train loss: 0.282, Train acc: 0.913
[2] Validation loss: 0.322, Validation acc: 0.897
22.824757502996363
157.55431658499583
23.636767329000577
157.5872638120054
22.35981481899944
158.14683463500114
22.987956970995583
158.16198553900176
24.055275287006225
158.00759851800103
[3] Train loss: 0.206, Train acc: 0.938
[3] Validation loss: 0.459, Validation acc: 0.849
25.476251559004595
158.47739934999845
23.980173511998146
157.79959627900098
24.018973701000505
158.12156627899822
22.920938933995785
158.12918127199373
24.30379478100076
158.20420325899613
[4] Train loss: 0.157, Train acc: 0.951
[4] Validation loss: 0.256, Validation acc: 0.916
23.652337959996657
158.59178901599807
22.527070137002738
158.3989356930033
23.379915040000924
158.22252161399956
22.68992300899845
164.8261088510044
23.93414262100123
171.65256655099802
25.671045435999986
170.502716160001
[5] Train loss: 0.119, Train acc: 0.963
[5] Validation loss: 0.359, Validation acc: 0.886
23.669062631000997
171.25960596399818
25.155041459998756
158.85544247699727
23.879419117001817
158.60356463099743
24.975107181999192
158.50659235400235
25.752248911994684
158.19933933200082
[6] Train loss: 0.096, Train acc: 0.970
[6] Validation loss: 0.178, Validation acc: 0.945
24.742835322002065
158.75738475599792
24.843694941999274
158.56112685699918
24.296167245003744
158.60015230499994
24.744902517995797
158.99702214999706
24.6638371010049
159.74558056899696
[7] Train loss: 0.069, Train acc: 0.981
[7] Validation loss: 0.183, Validation acc: 0.943
25.6931487979964
167.99857998899824
24.661441680997086
161.75666774400452
25.184828744997503
160.94075990599958
26.446800734003773
159.72927248199994
23.957009079000272
159.7572618810009
[8] Train loss: 0.056, Train acc: 0.984
[8] Validation loss: 0.150, Validation acc: 0.955
25.569492647002335
159.1571544460021
25.00364912999794
159.87246056000004
22.959265564000816
166.1273160339988
25.61123333100113
160.2729363920007
25.818705669000337
163.08156107200193
26.338960529996257
160.7520715339997
[9] Train loss: 0.041, Train acc: 0.989
[9] Validation loss: 0.162, Validation acc: 0.952
26.86553971200192
159.87005010700523
26.76637142499385
162.18104256800143
24.247632961996715
163.1489361720014
23.15476781599864
160.99469309599954
27.658713560005708
163.7659897449994
[10] Train loss: 0.032, Train acc: 0.992
[10] Validation loss: 0.157, Validation acc: 0.953
27.471770115000254
160.94895909900515
27.811097017001885
160.44377121899743
26.77036009800213
160.58364542300114
24.76528686999518
158.94773362200067
25.39222113199503
159.3891744249995
[11] Train loss: 0.022, Train acc: 0.995
[11] Validation loss: 0.154, Validation acc: 0.957
23.354908497996803
160.00580195400107
24.49700845500047
159.7829158569948
26.592962777998764
162.58890167999925
23.784558525003376
160.83701237200148
24.4013532329991
159.67269861399836
[12] Train loss: 0.017, Train acc: 0.997
[12] Validation loss: 0.154, Validation acc: 0.958
22.631614142002945
160.67983626200294
24.538883510998858
162.73476199200377
26.474662708002143
163.09510013100225
21.0368251530017
159.78175501600344
25.66782556099497
174.9085084660037
27.30350819999876
185.84644260099594
[13] Train loss: 0.012, Train acc: 0.998
[13] Validation loss: 0.153, Validation acc: 0.957
27.934902516994043
185.8892261630026
28.033359891000146
185.82443527300347
24.92786358599551
186.15565078899817
27.65743944499991
186.48721004599793
23.872616363994894
168.32513796199783
[14] Train loss: 0.008, Train acc: 0.999
[14] Validation loss: 0.158, Validation acc: 0.958
24.0157491630016
163.4597806390011
24.091126135994273
162.36159463399963
21.223385757999495
164.31092774200079
24.519255774997873
163.2885412320029
25.004652896997868
161.66236890199798
[15] Train loss: 0.007, Train acc: 1.000
[15] Validation loss: 0.157, Validation acc: 0.959
22.31261215199629
160.48509917299816
25.340359389003424
165.08657031299663
24.001621395997063
162.2613260959988
21.875731446001737
162.5430487670019
25.38291844000196
163.65582150899718
[16] Train loss: 0.005, Train acc: 1.000
[16] Validation loss: 0.161, Validation acc: 0.958
22.777649566000036
160.24991123600194
22.985239127003297
159.4545454350009
24.347382373001892
159.4633293339939
23.38724848599668
159.867144818003
24.042780904994288
160.41015607200097
[17] Train loss: 0.004, Train acc: 1.000
[17] Validation loss: 0.161, Validation acc: 0.959
23.641042229995946
160.80995818600059
23.863458530999196
159.52426684000238
24.97463215299649
159.73524113100575
24.229023724998115
160.00564373799716
24.990102268006012
159.73693625899614
21.874235203002172
160.7518833790018
[18] Train loss: 0.004, Train acc: 1.000
[18] Validation loss: 0.165, Validation acc: 0.958
22.782276566998917
160.1269633070042
24.232990024000173
161.80260722299863
26.385569805999694
161.6034256740022
25.262667720002355
167.46304956499807
24.712413242996263
165.98205100400082
[19] Train loss: 0.003, Train acc: 1.000
[19] Validation loss: 0.168, Validation acc: 0.960
23.971888621999824
165.69789913700515
23.892047010995157
167.13733828199474
24.658734133998223
160.09303947199805
22.703936976002296
160.4191959439995
23.296787049002887
159.86205075999897
[20] Train loss: 0.003, Train acc: 1.000
[20] Validation loss: 0.168, Validation acc: 0.960
22.410684305999894
160.45377493100386
26.710829349998676
159.9449436490031
23.843664418003755
159.73032894999778
25.773562434995256
159.7252263920018
23.222981131999404
159.8968610120064
[21] Train loss: 0.003, Train acc: 1.000
[21] Validation loss: 0.168, Validation acc: 0.959
25.089717835995543
159.95772496599966
26.362880606000545
160.0034693130001
23.436934008001117
160.36001952500374
24.617344273996423
159.8841109280038
24.387951698998222
160.52836104200105
23.790474164001353
160.5131878769971
[22] Train loss: 0.002, Train acc: 1.000
[22] Validation loss: 0.169, Validation acc: 0.959
23.350244467001176
160.55117953299487
25.195645313993737
160.30190088199743
24.08212903599633
160.3795528759947
23.837608615001955
160.44453971299663
25.454141818001517
160.55388113600202
[23] Train loss: 0.002, Train acc: 1.000
[23] Validation loss: 0.173, Validation acc: 0.958
24.383363174994884
162.046761839003
23.859888276005222
160.6445266630035
23.483293798002705
160.4760723099971
23.457996192999417
159.9224905469964
22.91474682700209
160.54302625399578
[24] Train loss: 0.002, Train acc: 1.000
[24] Validation loss: 0.175, Validation acc: 0.959
At epoch 23, lr changed to 0.010000000000000002
24.152486464001413
160.7373156350004
23.372656756997458
160.09919230700325
25.06646554300096
161.22299140199902
24.873939589997462
160.93469026599632
23.71090726499824
160.04414955600078
[25] Train loss: 0.002, Train acc: 1.000
[25] Validation loss: 0.173, Validation acc: 0.959
25.35138542200002
161.06039914499706
25.433963221999875
159.94794854700012
23.186001007001323
160.30670492200443
23.237016138002218
160.9752811340004
22.82482378399436
160.46032186700177
24.429291186002956
159.857205995002
[26] Train loss: 0.002, Train acc: 1.000
[26] Validation loss: 0.173, Validation acc: 0.959
24.75018896200345
160.89933624900004
23.053046089997224
160.79855505899468
24.67575208600465
160.81738063300145
23.475325395003892
161.4873093749993
21.8911068410016
161.2060214489975
[27] Train loss: 0.002, Train acc: 1.000
[27] Validation loss: 0.173, Validation acc: 0.959
24.01249505699525
160.0326304659975
23.434327149996534
161.24970418999874
23.31855356300366
161.0936052150064
23.24062932599918
160.5374484790009
25.23402825499943
161.29621273700468
[28] Train loss: 0.002, Train acc: 1.000
[28] Validation loss: 0.173, Validation acc: 0.959
23.893947411001136
161.51175282699842
24.708802503999323
160.6030828139992
23.672570907998306
161.01272625000274
21.893867753999075
161.1522135270061
21.303373932001705
161.056626384001
[29] Train loss: 0.002, Train acc: 1.000
[29] Validation loss: 0.173, Validation acc: 0.959
At epoch 28, lr changed to 0.0010000000000000002
23.352949572006764
161.24340860900702
24.056208018999314
160.45137436899677
23.37870777000353
160.98104947200045
24.499408335002954
161.57505896300427
23.212164210999617
160.54441637099808
[30] Train loss: 0.002, Train acc: 1.000
[30] Validation loss: 0.173, Validation acc: 0.959
25.161423823003133
160.94720425800188
24.478276316003758
161.07709262000571
23.56495175100281
161.1420971829939
22.61515136300295
160.89365189999808
22.660021620002226
161.76198554599978
22.69469575399853
161.97309801699885
[31] Train loss: 0.002, Train acc: 1.000
[31] Validation loss: 0.173, Validation acc: 0.959
25.355034822998277
161.2776504479989
22.52480807399843
161.03151852899464
23.69800936899992
161.00649732100283
23.29127159500058
161.56168646800506
25.201677383003698
161.09071344200493
[32] Train loss: 0.002, Train acc: 1.000
[32] Validation loss: 0.173, Validation acc: 0.959
24.801410325002507
161.77536630999384
23.35782451999694
161.19205157699616
20.746949444001075
160.8029854780034
23.9326858140048
161.6758411480041
22.976574300999346
161.34155261100386
[33] Train loss: 0.002, Train acc: 1.000
[33] Validation loss: 0.173, Validation acc: 0.959
24.648025414004223
161.73911063800188
24.97706357500283
161.83802206799737
23.209314691004693
161.31436743399536
25.44690869199985
161.63354944199818
25.417652023999835
161.56370056299784
[34] Train loss: 0.002, Train acc: 1.000
[34] Validation loss: 0.173, Validation acc: 0.959
Best_val_acc for lr = 0.1, sigma_w = 1.0, sigma_b = 0is 0.9598
